<!DOCTYPE HTML>
<!--
	Phantom by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Green Verge Project | University of Lincoln</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="inner">

							<!-- Logo -->
								<a href="index.html" class="logo">
									<span class="symbol"><img src="images/logo.png" alt="" /></span><span class="title"></span>
								</a>

							<!-- Nav -->
								<nav>
									<ul>
										<li><a href="#menu">Menu</a></li>
								
									</ul>
								</nav>

						</div>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<h2>Menu</h2>
						<ul>
							<li><a href="index.html">Home</a></li>
							<li><a href="project_summary.html">Project Introduction</a></li>
							<li><a href="dataset.html">Dataset and Annotations</a></li>
							<li><a href="deep_learning.html">Object Detection Model</a></li>
							<li><a href="mapping.html">Mapping</a></li>
							<li><a href="future.html">Future Work</a></li>
							<li><a href="about.html">About Us / Contact</a></li>
			
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">
						<div class="inner">
							<h2>Deep Learning Model</h2>
							<span class="image main"><img src="images/deep_learning_banner.jpg" alt="" /></span>
							
							<p>For object detection, we made use of the standard YOLOv5 architecture written in PyTorch. 
								Our model was trained on the 15,065 frames from our augmented dataset and the aerial dataset <a href ='https://github.com/UAVVaste/UAVVaste'> (https://github.com/UAVVaste)</a>, which contained a further 772 annotated images. 
								Qualitative results can be seen in the one of our demonstration videos below.
							</p>
							<h3>Demonstration Video</h3>
							<p align="center">
							<iframe width=75% height=430  src="https://www.youtube.com/embed/UDurw-crbLw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
						</p>
						<p></p>
						</div>
					</div>

					<!-- Footer -->
					<footer id="footer">
						<div class="inner">
							<ul class="copyright">
								<li>&copy; Green Verge Project | University of Lincoln. All rights reserved</li><li>Design: <a href="http://html5up.net">HTML5 UP.</a>
								</a></li>
							</ul>
					
					</footer>

			
  

  
  
			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>